{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение, ФЭН ВШЭ\n",
    "\n",
    "__Дата выдачи: 26.11.2017__\n",
    "__Дедлайн: 15.12.2017 23:59__\n",
    "\n",
    "# Практическое задание 4\n",
    "\n",
    "\n",
    "### О задании\n",
    "\n",
    "Практическое задание 4 посвящено ансамблям, bias-variance decomposition, деревьям и нейронным сетям. Обучение нейронных сетей займет какое-то время, поэтому не оставляйте эту часть на последний день!\n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце Вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник). \n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "\n",
    "### Формат сдачи\n",
    "Для сдачи задания переименуйте получившийся файл \\*.ipynb в соответствии со следующим форматом: *HW4_Username.ipynb*, где *Username* — Ваша фамилия и инициалы на латинице (например, *HW4_IvanovII.ipynb*). Далее отправьте этот файл на *ml.econom.hse@gmail.com* с темой *Практика {номер задания} - номер группы по данному курсу - Фамилия Имя* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Разложение ошибки на смещение и разброс\n",
    "#### Теоретическое вступление\n",
    "На занятиях мы разбирали примеры аналитического вычисления смещения и разброса нескольких алгоритмов обучения. Для большинства моделей данных и алгоритмов обучения аналитически рассчитать математические ожидания в формулах не удастся. Однако мат. ожидания можно оценивать приближенно. Чтобы оценить математическое ожидание $\\mathbb{E}_{\\bar x} f(\\bar x)$ функции от многомерной случайной величины $\\bar x = (x_1, \\dots, x_d)$, $\\bar x \\sim p(\\bar x)$, можно сгенерировать выборку из распределения $p(\\bar x)$ и усреднить значение функции на элементах этой выборки:\n",
    "$$\\mathbb{E}_{\\bar x} f(x) = \\int f(\\bar x) p(\\bar x) d \\bar x \\approx \\frac 1 m \\sum_{i=1}^m f(\\bar x_i), \\, \\bar x_i \\sim p(\\bar x), i = 1, \\dots, m.$$\n",
    "\n",
    "Для оценки многомерных интегралов ($d > 1$) объекты лучше генерировать, следуя специальным схемам, чтобы адекватно оценивать значение интеграла в областях высокой плотности. Мы не будем так усложнять задачу, а просто будем генерировать $\\bar x_i$ независимо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, оценим $\\mathbb{E}_x x^2,$ $x \\sim \\mathcal{N}(\\mu=5, \\sigma=3)$ (из теории вероятностей мы знаем, что\n",
    "$\\mathbb{E}_x x^2 = \\sigma^2 + \\mu^2 = 34$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(loc=5, scale=3, size=1000)\n",
    "(x**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или посчитаем многомерный интеграл $\\mathbb{E}_{\\bar x} \\bar x^T \\bar x = \\mathbb{E}_{\\bar x} \\sum_{i=1}^d x_i^2$, $\\bar x \\sim \\mathcal{N}(\\bar \\mu=(1, \\dots, 1), \\Sigma=I)$ при $d = 10$ (аналитический ответ 20):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 10\n",
    "X = np.random.multivariate_normal(np.ones(10), np.eye(10), size=1000)\n",
    "(X**2).sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы оценить интеграл по выборке, можно сгенерировать несколько выборок, вычислить на них значение функции и усреднить. Например, для интеграла $\\mathbb{E}_X [\\mu(X)(x)]$ генерируются выборки $X_1, \\dots, X_m$, на каждой из них обучается алгоритм $\\mu$ и делается предсказание для объекта $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Практическая часть\n",
    "#####  Построение \"среднего\" алгоритма $\\mathbb{E}_X [\\mu(X)]$\n",
    "В этом задании вам нужно построить графики, демонстрирующие, как алгоритм $\\mathbb{E}_X [\\mu(X)]$ аппроксимирует истинную зависимость в данных и как он меняется в зависимости от гиперпараметров метода обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.sin(x)   # истинная зависимость в данных\n",
    "sample_size = 100      # длина выборки\n",
    "samples_num = 20       # количество выборок\n",
    "linspace = np.linspace(0, 7, 1000)  # точки для построения графиков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1 (0.6 балла)__\n",
    "1. Сгенерируйте выборку x из одномерного экспоненциального распределения (np.random.exponential) длины sample_size.\n",
    "1. Создайте вектор целевых переменных y как сумму f(x) и случайного шума, сгенерированного из равномерного распределения на отрезке [-1, 1] (np.random.uniform).\n",
    "1. Обучите DecisionTreeRegressor с параметрами по умолчанию на полученной выборке и сделайте предсказания для объектов из linspace.\n",
    "1. Постройте два графика на одном рисунке: f(x) и зависимость, восстановленную решающим деревом.\n",
    "\n",
    "    Рекомендация: не забудьте, что все методы обучения в sklearn требуют на вход двумерную матрицу объекты-признаки. Сделать такую из одномерного вектора можно добавлением мнимых осей (np.newaxis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2 (0.6 балла):__\n",
    "\n",
    "Повторите первые 3 шага, описанные выше, samples_num раз. На одном графике для каждого обученного решающего дерева визуализируйте восстановленную им зависимость (рекомендуется все такие линии рисовать полупрозрачными и серым цветом: plt.plot(...... color=\"gray\", alpha=0.5)).  На этом же графике изобразите истинную зависимость f(x) (красным цветом: color=\"red\") и усредненную по всем деревьям восстановленную зависимость (черным цветом: color=\"black\").    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3 (0.2 балла):__\n",
    "Повторите предыдущий пункт, установив максимальную глубину решающего дерева равной 2, а затем равной 4. Таким образом, у вас получится еще два графика."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4 (0.6 балла)__ Что можно сказать о смещении решающих деревьев, исходя из проведенного эксперимента? В каких из трех рассмотренных случаев (без ограничения на глубину дерева и с ограничением 2 и 4) можно утверждать, что смещение решающего дерева близко к нулю?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(・・ ) ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5 (1 балл)__\n",
    "Проделайте тот же эксперимент с линейной регрессией и SVM с rbf ядром и параматрами $\\gamma = 1$, $\\gamma = 100$. Какие выводы можно сделать?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Решающие деревья"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5 (1 балл)__\n",
    "\n",
    "Загрузите следующие наборы данных (напомним, что pandas умеет загружать файлы по url, в нашем случае это файл \\*.data), предварительно ознакомившись с описанием признаков и целевой переменной в каждом из них (она записаны в Data Folder, в файле *.names): \n",
    "* [mushrooms](https://archive.ics.uci.edu/ml/datasets/Mushroom) (загрузили в предыдущем пункте, классы записаны в нулевом столбце),\n",
    "* [tic-rac-toe](https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame) (классы записаны в последнем столбце)\n",
    "* [cars](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation) (классы записаны в последнем столбце, считаем что unacc, acc - это класс 0, good, vgood - класс 1)\n",
    "* [nursery](https://archive.ics.uci.edu/ml/datasets/Nursery) (классы записаны в последнем столбце, считаем, что not_recom и recommend - класс 0, very_recom, priority, spec_prior - класс 1).\n",
    "\n",
    "Закодируйте категориальные признаки, использовав LabelEncoder. С помощью cross_val_score (cv=10) оцените accuracy на каждом из этих наборов данных следующих алгоритмов:\n",
    "* DecisionTreeClassifier, считающий все признаки вещественными\n",
    "* DecisionTreeClassfier, считающий все признаки категориальными\n",
    "* DecisionTreeClassifier, c корректным разбиением на категориальные и вещественные признаки.\n",
    "\n",
    "Рекомендации:\n",
    "* Чтобы cross_val_score вычисляла точность, нужно передать scoring=make_scorer(accuracy_score), обе фукнции из sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6 (0.5 балла)__\n",
    "\n",
    "Проанализируйте результаты эксперимента. \n",
    "Одинаково ли для разных наборов данных ранжируются алгоритмы? \n",
    "Порассуждайте, почему так происходит. \n",
    "\n",
    "Обратите внимание на значение признаков в разных наборах данных. \n",
    "Присутствует ли в результатах какая-то компонента случайности? \n",
    "Можно ли повлиять на нее и улушить работу алгоритмов?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(・・ ) ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### III. Композиции деревьев\n",
    "#### Сравнение композиционных методов над решающими деревьями\n",
    "__7 (1 балл)__\n",
    "\n",
    "Выполните следующие шаги:\n",
    "1. Загрузите датасет [winequality-red.csv](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv) в датафрейм. Последний столбец - целевая переменная (содержит классы).\n",
    "1. С помощью cross_val_score с cv=3 оцените качество (accuracy) следующих классификаторов:\n",
    "    * DecisionTreeClassifier\n",
    "    * BaggingClassifier со 100 деревьями\n",
    "    * BaggingClassifier со 100 деревьями; каждое дерево обучается только по половине случайно выбранных признаков (см. параметры метода)\n",
    "    * RandomForestClassifier со 100 деревьями\n",
    "    \n",
    "Значение получается шумное, но в целом у вас должно получиться, что качество возрастает с каждым следующим алгоритмом. Этот пример демонстрирует, что RandomForest - это более сложный алгоритм, чем бэггинг и бэггинг со случайными подпространствами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Число деревьев в случайном лесе\n",
    "В этой задаче мы рассмотрим, переобучаются ли композиционные алгоритмы с увеличением числа деревьев.\n",
    "\n",
    "__8 (1 балл)__\n",
    "\n",
    "Продолжим работать с набором данных [winequality-red.csv](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv). Разделите выборку на обучение и контроль с пропорции 7:3, предварительно перемешав объекты. Переберите значения от 100 до 5000 деревьев с шагом 100, посчитайте accuracy на тестовой выборке для каждого числа деревьев и постройте график зависимости качества от числа деревьев.\n",
    "\n",
    "Рекомендация.\n",
    "\n",
    "Если каждый раз обучать RandomForest с нуля, придётся обучить в общей сумме $100 + 200 + \\ldots + 5000$ деревьев.\n",
    "Однако, как мы знаем, деревья в случайных лесах строятся независимо и параллельно, поэтому можно обучить всего 5000 деревьев.\n",
    "\n",
    "Для этого в при создании объекта класса RandomForestClassifier нужно указать в том числе warm_start=True. Затем обучить алгоритм с помощью метода fit, использовать метод predict для классификации. После этого с помощью метода set_params изменить параметр n_estimators. Если к полученному объекту применить метод fit, внутри него будет обучаться только недостающее число деревьев.\n",
    "\n",
    "Переобучается ли случайный лес с увеличением числа деревьев?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Нейронные сети\n",
    "\n",
    "*На обучение нейросетей может уйти больше часа, не откладывайте этот пункт на последний день*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__9 (1 балл)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании вам предстоит обучить нейронную сеть на датасете [MNIST](https://en.wikipedia.org/wiki/MNIST_database) с помощью пакета [keras](https://keras.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите нейронную сеть с двумя скрытыми слоями в каждой из которых поместите по 100 нейронов. Какого качества удается добиться на тесте?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__10 (2 балл)__\n",
    "Добавьте сверточные и pooling слои (вы можете также убрать Dense слои), добейтесь большего качества. Для успешного выполнения задания получите accuracy больше 0.99 на тестовой выборке. \n",
    "\n",
    "Рекомендации: после сверточных слоев наиболее эффективно добавлять MaxPooling слои, в конце перед последним слоем поставьте Dense слои с достаточно большим количеством нейронов. Подвигайте количество слоев, learning rate, функции активации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__11 (1 балл)__\n",
    "Добавьте 1 или 2 dropout слоя внутрь сети предыдущего шага. Удается ли добиться большего качества? Что происходит с процессом обучения? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
